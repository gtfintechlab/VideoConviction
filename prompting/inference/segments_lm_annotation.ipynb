{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code is in python 3.10 +. Need to reflect that in environment yaml. \n",
    "\n",
    "output_df.to_csv(\n",
    "        f'../llm_prompt_s_transcript_outputs/{model_name.replace(\"/\", \"_\")}_{today.strftime(\"%d_%m_%Y\")}.csv',\n",
    "        index=False\n",
    "    )\n",
    "\n",
    "Did not run deekseek. deepseek-ai/DeepSeek-R1 Need to have Agam run it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import sleep, time\n",
    "from datetime import date\n",
    "import threading\n",
    "from typing import Tuple\n",
    "from datasets import load_dataset\n",
    "from openai import OpenAI\n",
    "import google.generativeai as genai\n",
    "from google.ai import generativelanguage as glm\n",
    "import json\n",
    "from datetime import datetime\n",
    "import re\n",
    "import anthropic\n",
    "today = date.today()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure APIs and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't want to use environmental variables you can add your api key directly to api_key\n",
    "togetherai_api_key = os.environ.get('TOGETHERAI_API_KEY')\n",
    "openai_api_key = os.environ.get('OPENAI_API_KEY')\n",
    "google_api_key = os.environ.get('GOOGLE_API_KEY')\n",
    "anthropic_api_key = os.environ.get('ANTHROPIC_API_KEY')\n",
    "\n",
    "# together.ai key\n",
    "client_together = OpenAI(api_key=togetherai_api_key,\n",
    "                base_url='https://api.together.xyz')\n",
    "\n",
    "#  OpenAI key\n",
    "client_openai = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "# Gemini key (https://ai.google.dev/gemini-api/docs/quickstart?lang=python)\n",
    "genai.configure(api_key=google_api_key)\n",
    "\n",
    "# Anthropic API Key\n",
    "client_anthropic = anthropic.Anthropic(api_key=anthropic_api_key)\n",
    "\n",
    "def get_safety_settings():\n",
    "    \"\"\" \n",
    "    Google API Specific\n",
    "    Set the block threshold to None for each harm category\n",
    "    Refer https://ai.google.dev/gemini-api/docs/safety-settings to modify the safety settings\n",
    "    Gemini model information: https://ai.google.dev/gemini-api/docs/models/gemini#gemini-1.5-pro\n",
    "    \"\"\"\n",
    "    safety_settings = [\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_DANGEROUS\",\n",
    "        \"threshold\": \"BLOCK_NONE\",\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
    "        \"threshold\": \"BLOCK_NONE\",\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
    "        \"threshold\": \"BLOCK_NONE\",\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "        \"threshold\": \"BLOCK_NONE\",\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
    "        \"threshold\": \"BLOCK_NONE\",\n",
    "    },\n",
    "    ]\n",
    "    return safety_settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do not need this line for the segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "\n",
    "#data_directory = '../process_annotations_pipeline/data_sources/'\n",
    "\n",
    "#video_transcripts = pd.read_csv(data_directory + 'full_raw_video_transcripts.csv')\n",
    "#video_metadata = pd.read_csv(data_directory + 'inner_id_to_video_metadata.csv')\n",
    "\n",
    "#video_transcripts.rename(columns = {'transcript_video_id': 'video_id'},\n",
    "#                         inplace = True)\n",
    "\n",
    "# Merging dataframes\n",
    "#df = video_transcripts.merge(\n",
    "#    video_metadata[['video_id', 'original_video_title']],  # Selecting only video_id and original_video_title from video_metadata\n",
    "#    on='video_id',                              # Merging on the video_id column\n",
    "#    how='left'                                 # Keeping all rows from video_transcripts\n",
    "#)\n",
    "\n",
    "# Yash has 288\n",
    "#len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(series, lm_type = \"lm\", whole = True, price = False):\n",
    "    \"\"\"\n",
    "    Generates a structured prompt based on the provided title, transcript, language model type, and whether we.\n",
    "\n",
    "    Args:\n",
    "        series (pd.Series): The pandas series  \n",
    "        lm_type (str, optional): The type of language model the prompt is intended for (default is \"lm\").\n",
    "                                 Options are \"lm\" or \"vlm\". vlm has a slightly larger prompt to incorporate facial expression.\n",
    "        whole (bool, optional): Specifies whether to use the entire transcript (True) or a subset (False).\n",
    "                                Defaults to True.\n",
    "        price (bool, optional): Only available for vlm. Can the vlm detect price.\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted prompt stored in the variable `prompt`, ready for input into a language model.\n",
    "    \"\"\"\n",
    "\n",
    "    # title\n",
    "    # transcript\n",
    "    # 'segment_transcript'\n",
    "\n",
    "    title = series['video_title']\n",
    "\n",
    "    if whole == True:\n",
    "        transcript = series['transcript']\n",
    "    if whole == False:   \n",
    "        segment_transcript = series['segment_transcript']\n",
    "    \n",
    "    if lm_type == \"vlm\":\n",
    "        facial_expression = (\"\\n           - Facial Expressions: Neutral or doubtful (furrowed brows, pursed lips).\",\n",
    "                             \"\\n           - Facial Expressions: Moderate enthusiasm (mild smiles, slightly raised eyebrows).\",\n",
    "                             \"\\n           - Facial Expressions: Enthusiastic, energetic (wide smiles, raised eyebrows).\")\n",
    "    else:\n",
    "        facial_expression = (\"\",\n",
    "                             \"\",\n",
    "                             \"\")\n",
    "\n",
    "    if whole == True:\n",
    "        whole_transcript_specific = (\" and video title\",\n",
    "                            f\"\"\"Inputs:\n",
    "    - Video Title: {title}\n",
    "    - Transcript: {transcript}\"\"\",\n",
    "                            \"\\n           - Consistency: Low conviction if the title makes a bold claim, but the transcript lacks matching conviction.\",\n",
    "                            \"\\n           - Consistency: Medium conviction if the title makes a bold claim, followed by consistent confidence in the transcript.\",\n",
    "                            \"\\n           - Consistency: High conviction if the title and transcript are strongly aligned.\")\n",
    "    else:\n",
    "        whole_transcript_specific = (\"\",\n",
    "                            f\"\"\"Inputs:\n",
    "    - Transcript: {segment_transcript}\"\"\",\n",
    "                             \"\",\n",
    "                             \"\",\n",
    "                            \"\")\n",
    "        \n",
    "\n",
    "    prompt = f\"\"\"Analyze the YouTube video transcript{whole_transcript_specific[0]} of influencers discussing the US stock market, focusing on stock recommendations and their conviction.\n",
    "    \n",
    "    {whole_transcript_specific[1]}\n",
    "    \n",
    "    Instructions:\n",
    "    1. Does the video contain any stock recommendations:\n",
    "       - Label this as `Stock Recommendations Present` with either \"Yes\" or \"No\".\n",
    "    \n",
    "    2. If `Stock Recommendations Present` is \"Yes\", create a list under the key `Recommendations`. Each recommendation should follow this structure:{{\"Action\": \"Buy | Hold | Don't Buy | Sell | Short Sell | Unclear\",\n",
    "         \"Justification\": \"Brief explanation for the action based on the transcript\",\n",
    "         \"Conviction Score\": \"1 | 2 | 3\",\n",
    "         \"Ticker Name\": \"Ticker name\"}}\n",
    "    \n",
    "       Details for each field:\n",
    "       - `Action`: Categorize each stock recommendation as:\n",
    "         - \"Buy\": Purchase shares of the stock.\n",
    "         - \"Hold\":  Retain the stock if already owned, without necessarily\n",
    "    buying more.\n",
    "         - \"Don't Buy\": Refrain from purchasing the stock.\n",
    "         - \"Sell\": Sell shares of the stock currently owned.\n",
    "         - \"Short Sell\": Sell shares not currently owned, intending to\n",
    "    buy them back later at a lower price.\n",
    "         - \"Unclear\": When the action is not explicitly stated.\n",
    "       - `Justification`: Provide a brief explanation for the action based on the transcript.\n",
    "       - `Conviction Score`: Assign a score based on the following criteria:\n",
    "         - \"1\" (Low Conviction):\n",
    "           - Tone: Hesitant or uncertain language, frequent qualifiers (e.g., “maybe,” “possibly”).{facial_expression[0]}\n",
    "           - Delivery: Reserved or doubtful language.{whole_transcript_specific[2]}\n",
    "         - \"2\" (Moderate Conviction):\n",
    "           - Tone: Relatively confident language with some qualifiers.{facial_expression[1]}\n",
    "           - Delivery: Balanced and moderately positive language.{whole_transcript_specific[3]}\n",
    "         - \"3\" (High Conviction):\n",
    "           - Tone: Strong, assertive language without hesitation.{facial_expression[2]}\n",
    "           - Delivery: Decisive recommendations with no qualifiers.{whole_transcript_specific[4]}\n",
    "       - `Ticker Name`: Specify the ticker name of the stock being discussed.\n",
    "    \n",
    "    3. If `Stock Recommendations Present` is \"No\", return the following structure:{{\"Stock Recommendations Present\": \"No\",\n",
    "         \"Recommendations\": []\n",
    "       }}\n",
    "    \n",
    "    \n",
    "    Output Requirements:\n",
    "    - Return only valid JSON that can be directly parsed by JSON libraries.\n",
    "    - Do not include any additional text, comments, formatting indicators (e.g., `json` or backticks), or explanatory content.\n",
    "    \"\"\"\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_model(prompt: str,\n",
    "                    model_source: str,\n",
    "                    model_name: str,\n",
    "                    temperature: float) -> str:\n",
    "    \"\"\"\n",
    "    Generates a structured prompt based on the provided title, transcript, language model type, and other options.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The input prompt.\n",
    "        model_source (str): Source of the model (e.g., 'OpenAI', 'Gemini', or other specified sources).\n",
    "        model_name (str): Name of the model.\n",
    "        temperature (float): Temperature setting for the model.\n",
    "        \n",
    "    Returns:\n",
    "        str: A string formatted as JSON or output from the model.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt_json = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    try:\n",
    "        match model_source:\n",
    "            # Try to make Max output tokens\n",
    "            case \"OpenAI\":\n",
    "                model_str = model_name\n",
    "                chat_completion = client_openai.chat.completions.create(\n",
    "                    model=model_str,\n",
    "                    messages=prompt_json,\n",
    "                    temperature=temperature,\n",
    "                    max_tokens=2048\n",
    "                )\n",
    "                prompt_output = chat_completion.choices[0].message.content\n",
    "\n",
    "            case \"Gemini\":\n",
    "                model_str = model_name\n",
    "                safety_settings = get_safety_settings()\n",
    "                # Initialize the model once before the iteration over the rows begin.\n",
    "                # Link below takes about how to deal with json markdown output\n",
    "                # https://medium.com/google-cloud/how-to-consistently-output-json-with-the-gemini-api-using-controlled-generation-887220525ae0\n",
    "                model = genai.GenerativeModel(model_name = model_str, \\\n",
    "                                              safety_settings = safety_settings,\n",
    "                                              generation_config=genai.GenerationConfig(\\\n",
    "                                                  max_output_tokens=2048,\\\n",
    "                                                  response_mime_type=\"application/json\",\\\n",
    "                                                    temperature=temperature)\n",
    "                                            )\n",
    "                \n",
    "                response = model.generate_content(prompt)\n",
    "                \n",
    "                if response.text:\n",
    "                    prompt_output = response.text\n",
    "                else:\n",
    "                    print(\"Prompt:\", prompt)\n",
    "                    if response.prompt_feedback:\n",
    "                        print(\"Prompt Feedback: \", response.prompt_feedback)\n",
    "                    if response.candidates[0].finish_reason != glm.Candidate.FinishReason.STOP:\n",
    "                        print(\"Prompt Finish reason: \", response.candidates[0].finish_reason)\n",
    "                        print(\"Prompt Safety Warnings: \", response.candidates[0].safety_ratings)\n",
    "                    prompt_output = \"\"\n",
    "\n",
    "            case \"Anthropic\":\n",
    "                response = client_anthropic.messages.create(\n",
    "                    model=model_name, # Takes parsed parameter in function and uses that model for inference\n",
    "                    temperature = temperature,\n",
    "                    max_tokens=2048,\n",
    "                    messages=[\n",
    "                        {\n",
    "                            \"role\": \"user\", \n",
    "                            \"content\": prompt\n",
    "                        }\n",
    "                    ]\n",
    "                )\n",
    "            \n",
    "                prompt_output = response.content[0].text\n",
    "\n",
    "            case _:\n",
    "                model_str = model_name\n",
    "                chat_completion = client_together.chat.completions.create(\n",
    "                    model=model_str,\n",
    "                    messages=prompt_json,\n",
    "                    temperature=temperature,\n",
    "                    max_tokens=2048\n",
    "                )\n",
    "                prompt_output = chat_completion.choices[0].message.content\n",
    "\n",
    "        # Don't inference too fast\n",
    "        sleep(0.4)\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        sleep(10.0)\n",
    "        prompt_output = \"\"\n",
    "\n",
    "    # Basic cleaning of ```json start\n",
    "    # https://community.openai.com/t/json-returning-with-json/584818/8\n",
    "    def clean_json_string(json_string):\n",
    "        pattern = r'^```json\\s*(.*?)\\s*```$'\n",
    "        cleaned_string = re.sub(pattern, r'\\1', json_string, flags=re.DOTALL)\n",
    "        return cleaned_string.strip()\n",
    "\n",
    "    prompt_output = clean_json_string(prompt_output).strip('```')\n",
    "    \n",
    "    # Remove triple backticks for a couple models that output them \n",
    "    return prompt_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprompt_output = inference_model(prompt = prompt,\\n                model_source =  \"Anthropic\",\\n                model_name = \"claude-3-5-sonnet-20241022\",\\n                temperature = 0)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "prompt_output = inference_model(prompt = prompt,\n",
    "                model_source =  \"Anthropic\",\n",
    "                model_name = \"claude-3-5-sonnet-20241022\",\n",
    "                temperature = 0)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(prompt_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental Section to Verify Prompt Before Rerunning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"../data_needed_for_inference/complete_dataset.csv\")\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    # Extract title and transcript\n",
    "    series = row\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = create_prompt(series = series,\n",
    "              lm_type = 'lm',\n",
    "              whole = False,\n",
    "              price = False\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyze the YouTube video transcript of influencers discussing the US stock market, focusing on stock recommendations and their conviction.\n",
      "    \n",
      "    Inputs:\n",
      "    - Transcript:  these in a minute. First up is $225 million dollar Veritone Inc., ticker V-E-R-I, a cloud-based AI platform that structures audio and video data. And now Nation, if that sounds like a bunch of tech jargon, just understand that Veritone is in the convergence of what's going to be the three biggest trends over the next decade. Data analysis of audio and video content, cloud-based connectivity, and an AI platform that learns to become more effective. And the potential markets for these speak for themselves. The company's AIware platform is facing markets with double-digit annual growth and tens of billions in opportunities. Revenue has jumped 244% in the last two years and was even able to increase in that tough second quarter. Analysts have price targets ranging from $15 a share to as high as $18 each over the next year for a potential 120% return.\n",
      "    \n",
      "    Instructions:\n",
      "    1. Does the video contain any stock recommendations:\n",
      "       - Label this as `Stock Recommendations Present` with either \"Yes\" or \"No\".\n",
      "    \n",
      "    2. If `Stock Recommendations Present` is \"Yes\", create a list under the key `Recommendations`. Each recommendation should follow this structure:{\"Action\": \"Buy | Hold | Don't Buy | Sell | Short Sell | Unclear\",\n",
      "         \"Justification\": \"Brief explanation for the action based on the transcript\",\n",
      "         \"Conviction Score\": \"1 | 2 | 3\",\n",
      "         \"Ticker Name\": \"Ticker name\"}\n",
      "    \n",
      "       Details for each field:\n",
      "       - `Action`: Categorize each stock recommendation as:\n",
      "         - \"Buy\": Purchase shares of the stock.\n",
      "         - \"Hold\":  Retain the stock if already owned, without necessarily\n",
      "    buying more.\n",
      "         - \"Don't Buy\": Refrain from purchasing the stock.\n",
      "         - \"Sell\": Sell shares of the stock currently owned.\n",
      "         - \"Short Sell\": Sell shares not currently owned, intending to\n",
      "    buy them back later at a lower price.\n",
      "         - \"Unclear\": When the action is not explicitly stated.\n",
      "       - `Justification`: Provide a brief explanation for the action based on the transcript.\n",
      "       - `Conviction Score`: Assign a score based on the following criteria:\n",
      "         - \"1\" (Low Conviction):\n",
      "           - Tone: Hesitant or uncertain language, frequent qualifiers (e.g., “maybe,” “possibly”).\n",
      "           - Delivery: Reserved or doubtful language.\n",
      "         - \"2\" (Moderate Conviction):\n",
      "           - Tone: Relatively confident language with some qualifiers.\n",
      "           - Delivery: Balanced and moderately positive language.\n",
      "         - \"3\" (High Conviction):\n",
      "           - Tone: Strong, assertive language without hesitation.\n",
      "           - Delivery: Decisive recommendations with no qualifiers.\n",
      "       - `Ticker Name`: Specify the ticker name of the stock being discussed.\n",
      "    \n",
      "    3. If `Stock Recommendations Present` is \"No\", return the following structure:{\"Stock Recommendations Present\": \"No\",\n",
      "         \"Recommendations\": []\n",
      "       }\n",
      "    \n",
      "    \n",
      "    Output Requirements:\n",
      "    - Return only valid JSON that can be directly parsed by JSON libraries.\n",
      "    - Do not include any additional text, comments, formatting indicators (e.g., `json` or backticks), or explanatory content.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference All for Given Model (Segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to run for ```whole``` models CHANGE THE PROMPT parameter, output path, and check above prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all_lms = {\"claude-3-opus-20240229\": \"Anthropic\", \n",
    "           \"claude-3-5-haiku-20241022\": \"Anthropic\", \n",
    "           \"claude-3-5-sonnet-20241022\": \"Anthropic\",\n",
    "           \"deepseek-ai/DeepSeek-R1\": \"Together AI\",\n",
    "           \"deepseek-ai/DeepSeek-V3\": \"Together AI\",\n",
    "           \"gemini-1.5-pro-002\": \"Gemini\",\n",
    "           \"gpt-4o-2024-08-06\": \"OpenAI\",\n",
    "           \"gpt-4o-mini-2024-07-18\": \"OpenAI\",\n",
    "           \"gpt-4-turbo-2024-04-09\": \"OpenAI\",\n",
    "           \"meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo\": \"Together AI\",\n",
    "           \"meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo\": \"Together AI\",\n",
    "           \"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\": \"Together AI\",\n",
    "           \"Qwen/Qwen2.5-72B-Instruct-Turbo\": \"Together AI\",\n",
    "           \"Qwen/Qwen2.5-7B-Instruct-Turbo\": \"Together AI\",\n",
    "           \"mistralai/Mistral-7B-Instruct-v0.1\": \"Together AI\",\n",
    "           \"mistralai/Mixtral-8x7B-Instruct-v0.1\": \"Together AI\",\n",
    "           \"mistralai/Mixtral-8x22B-Instruct-v0.1\": \"Together AI\",\n",
    "          }\n",
    "\n",
    "DID NOT RUN DEEKSEEK \n",
    "\n",
    "\"deepseek-ai/DeepSeek-R1\": \"Together AI\",\n",
    "\n",
    "           \"deepseek-ai/DeepSeek-V3\": \"Together AI\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'derived_inner_id', 'video_id', 'start', 'end', 'action',\n",
      "       'action_source', 'conviction_score', 'ticker_name', 'action_date',\n",
      "       'price', 'quantity', 'video_title', 'annotation_id', 'annotator',\n",
      "       'is_rec_present', 'original_inner_id', 'original_video_title',\n",
      "       'publishedAt', 'channelId', 'channelTitle', 'videoDescription', 'tags',\n",
      "       'defaultAudioLanguage', 'duration', 'isCaptionAvailable', 'viewCount',\n",
      "       'likeCount', 'favoriteCount', 'commentCount', 'comments',\n",
      "       'channelDescription', 'channelViewCount', 'channelSubscriberCount',\n",
      "       'videoCount', 'channelCategory', 'transcript', 'youtube_video_url',\n",
      "       'segment_transcript'],\n",
      "      dtype='object')\n",
      "(381, 39)\n"
     ]
    }
   ],
   "source": [
    "## Segments\n",
    "\n",
    "df = pd.read_csv(\"../data_needed_for_inference/complete_dataset.csv\")\n",
    "\n",
    "print(df.columns)\n",
    "\n",
    "# Selected region and only if rec is present. (381 videos)\n",
    "# Applying all the filters using .loc\n",
    "filtered_df = df.loc[\n",
    "    (df['action_source'] == \"Selected region\") & \n",
    "    (df['is_rec_present'] == \"Yes\") &\n",
    "    (~df['transcript'].isna()) & \n",
    "    (df['transcript'].str.strip() != \"\") & \n",
    "    (df['transcript'].str.split().str.len() >= 3)\n",
    "]\n",
    "\n",
    "df = filtered_df.copy()\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>derived_inner_id</th>\n",
       "      <th>video_id</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>action</th>\n",
       "      <th>action_source</th>\n",
       "      <th>conviction_score</th>\n",
       "      <th>ticker_name</th>\n",
       "      <th>action_date</th>\n",
       "      <th>...</th>\n",
       "      <th>commentCount</th>\n",
       "      <th>comments</th>\n",
       "      <th>channelDescription</th>\n",
       "      <th>channelViewCount</th>\n",
       "      <th>channelSubscriberCount</th>\n",
       "      <th>videoCount</th>\n",
       "      <th>channelCategory</th>\n",
       "      <th>transcript</th>\n",
       "      <th>youtube_video_url</th>\n",
       "      <th>segment_transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>125899618</td>\n",
       "      <td>1</td>\n",
       "      <td>0CJU8R4oNFk</td>\n",
       "      <td>197.798669</td>\n",
       "      <td>267.774387</td>\n",
       "      <td>Buy</td>\n",
       "      <td>Selected region</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ZYXI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>168.0</td>\n",
       "      <td>[\".I don’t who, but someone actually needs to ...</td>\n",
       "      <td>Welcome to your chance to create the financial...</td>\n",
       "      <td>43592318</td>\n",
       "      <td>641000</td>\n",
       "      <td>1168</td>\n",
       "      <td>Category 1</td>\n",
       "      <td>Hey Bowtie Nation, Joseph Hogue here with the...</td>\n",
       "      <td>https://www.youtube.com/watch?v=0CJU8R4oNFk</td>\n",
       "      <td>up and make your first deposit. Zynex, ticker...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>125899618</td>\n",
       "      <td>1</td>\n",
       "      <td>0CJU8R4oNFk</td>\n",
       "      <td>515.435925</td>\n",
       "      <td>559.602978</td>\n",
       "      <td>Buy</td>\n",
       "      <td>Selected region</td>\n",
       "      <td>3.0</td>\n",
       "      <td>KRMD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>168.0</td>\n",
       "      <td>[\".I don’t who, but someone actually needs to ...</td>\n",
       "      <td>Welcome to your chance to create the financial...</td>\n",
       "      <td>43592318</td>\n",
       "      <td>641000</td>\n",
       "      <td>1168</td>\n",
       "      <td>Category 1</td>\n",
       "      <td>Hey Bowtie Nation, Joseph Hogue here with the...</td>\n",
       "      <td>https://www.youtube.com/watch?v=0CJU8R4oNFk</td>\n",
       "      <td>next few years. Our next pick here is a healt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>125899618</td>\n",
       "      <td>1</td>\n",
       "      <td>0CJU8R4oNFk</td>\n",
       "      <td>560.518396</td>\n",
       "      <td>614.246246</td>\n",
       "      <td>Buy</td>\n",
       "      <td>Selected region</td>\n",
       "      <td>2.0</td>\n",
       "      <td>IRMD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>168.0</td>\n",
       "      <td>[\".I don’t who, but someone actually needs to ...</td>\n",
       "      <td>Welcome to your chance to create the financial...</td>\n",
       "      <td>43592318</td>\n",
       "      <td>641000</td>\n",
       "      <td>1168</td>\n",
       "      <td>Category 1</td>\n",
       "      <td>Hey Bowtie Nation, Joseph Hogue here with the...</td>\n",
       "      <td>https://www.youtube.com/watch?v=0CJU8R4oNFk</td>\n",
       "      <td>Our next stock to buy here, Iradomid, ticker ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>125899621</td>\n",
       "      <td>4</td>\n",
       "      <td>1Gm4A7EFYI4</td>\n",
       "      <td>39.577461</td>\n",
       "      <td>642.953845</td>\n",
       "      <td>Buy</td>\n",
       "      <td>Selected region</td>\n",
       "      <td>3.0</td>\n",
       "      <td>V</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>231.0</td>\n",
       "      <td>['What was the most recent stock you added to ...</td>\n",
       "      <td>This channel is all about reaching financial f...</td>\n",
       "      <td>7923235</td>\n",
       "      <td>58000</td>\n",
       "      <td>700</td>\n",
       "      <td>Category 1</td>\n",
       "      <td>So I've had my eye on a few different stocks ...</td>\n",
       "      <td>https://www.youtube.com/watch?v=1Gm4A7EFYI4</td>\n",
       "      <td>Isa, I've been teasing this one for the last ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>125899622</td>\n",
       "      <td>5</td>\n",
       "      <td>1Lx7z_x4Rc0</td>\n",
       "      <td>118.724770</td>\n",
       "      <td>320.404668</td>\n",
       "      <td>Sell</td>\n",
       "      <td>Selected region</td>\n",
       "      <td>3.0</td>\n",
       "      <td>SOFI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>77.0</td>\n",
       "      <td>[\"Come on over today and take your next step i...</td>\n",
       "      <td>The Stock Moe YouTube channel tries to bring t...</td>\n",
       "      <td>85876827</td>\n",
       "      <td>625000</td>\n",
       "      <td>2710</td>\n",
       "      <td>Category 1</td>\n",
       "      <td>Family we absolutely dominated it today. If y...</td>\n",
       "      <td>https://www.youtube.com/watch?v=1Lx7z_x4Rc0</td>\n",
       "      <td>I sold SoFi. SoFi has been good, it's been re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  derived_inner_id     video_id       start         end action  \\\n",
       "1   125899618                 1  0CJU8R4oNFk  197.798669  267.774387    Buy   \n",
       "3   125899618                 1  0CJU8R4oNFk  515.435925  559.602978    Buy   \n",
       "4   125899618                 1  0CJU8R4oNFk  560.518396  614.246246    Buy   \n",
       "9   125899621                 4  1Gm4A7EFYI4   39.577461  642.953845    Buy   \n",
       "10  125899622                 5  1Lx7z_x4Rc0  118.724770  320.404668   Sell   \n",
       "\n",
       "      action_source  conviction_score ticker_name action_date  ...  \\\n",
       "1   Selected region               2.0        ZYXI         NaN  ...   \n",
       "3   Selected region               3.0        KRMD         NaN  ...   \n",
       "4   Selected region               2.0        IRMD         NaN  ...   \n",
       "9   Selected region               3.0           V         NaN  ...   \n",
       "10  Selected region               3.0        SOFI         NaN  ...   \n",
       "\n",
       "    commentCount                                           comments  \\\n",
       "1          168.0  [\".I don’t who, but someone actually needs to ...   \n",
       "3          168.0  [\".I don’t who, but someone actually needs to ...   \n",
       "4          168.0  [\".I don’t who, but someone actually needs to ...   \n",
       "9          231.0  ['What was the most recent stock you added to ...   \n",
       "10          77.0  [\"Come on over today and take your next step i...   \n",
       "\n",
       "                                   channelDescription  channelViewCount  \\\n",
       "1   Welcome to your chance to create the financial...          43592318   \n",
       "3   Welcome to your chance to create the financial...          43592318   \n",
       "4   Welcome to your chance to create the financial...          43592318   \n",
       "9   This channel is all about reaching financial f...           7923235   \n",
       "10  The Stock Moe YouTube channel tries to bring t...          85876827   \n",
       "\n",
       "   channelSubscriberCount videoCount  channelCategory  \\\n",
       "1                  641000       1168       Category 1   \n",
       "3                  641000       1168       Category 1   \n",
       "4                  641000       1168       Category 1   \n",
       "9                   58000        700       Category 1   \n",
       "10                 625000       2710       Category 1   \n",
       "\n",
       "                                           transcript  \\\n",
       "1    Hey Bowtie Nation, Joseph Hogue here with the...   \n",
       "3    Hey Bowtie Nation, Joseph Hogue here with the...   \n",
       "4    Hey Bowtie Nation, Joseph Hogue here with the...   \n",
       "9    So I've had my eye on a few different stocks ...   \n",
       "10   Family we absolutely dominated it today. If y...   \n",
       "\n",
       "                              youtube_video_url  \\\n",
       "1   https://www.youtube.com/watch?v=0CJU8R4oNFk   \n",
       "3   https://www.youtube.com/watch?v=0CJU8R4oNFk   \n",
       "4   https://www.youtube.com/watch?v=0CJU8R4oNFk   \n",
       "9   https://www.youtube.com/watch?v=1Gm4A7EFYI4   \n",
       "10  https://www.youtube.com/watch?v=1Lx7z_x4Rc0   \n",
       "\n",
       "                                   segment_transcript  \n",
       "1    up and make your first deposit. Zynex, ticker...  \n",
       "3    next few years. Our next pick here is a healt...  \n",
       "4    Our next stock to buy here, Iradomid, ticker ...  \n",
       "9    Isa, I've been teasing this one for the last ...  \n",
       "10   I sold SoFi. SoFi has been good, it's been re...  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mistralai/Mixtral-8x22B-Instruct-v0.1\n",
      "Processed 50 rows out of 381\n",
      "Processed 100 rows out of 381\n",
      "Processed 150 rows out of 381\n",
      "Processed 200 rows out of 381\n",
      "Processed 250 rows out of 381\n",
      "Processed 300 rows out of 381\n",
      "Processed 350 rows out of 381\n"
     ]
    }
   ],
   "source": [
    "all_lms = {\"mistralai/Mixtral-8x22B-Instruct-v0.1\": \"Together AI\",}\n",
    "\n",
    "# Loop through each model\n",
    "for model_name, model_source in all_lms.items():\n",
    "    print(model_name)\n",
    "\n",
    "    # Prepare a DataFrame to store results\n",
    "    output_df = pd.DataFrame(columns=[\n",
    "        'video_id',\n",
    "        'video_title',\n",
    "        'transcript',\n",
    "        'model_source',\n",
    "        'model_name',\n",
    "        'date_of_inference',\n",
    "        'prompt_used',\n",
    "        'prompt_output',\n",
    "        'video_source'\n",
    "    ])\n",
    "    \n",
    "\n",
    "    # Initialize a counter\n",
    "    iteration_count = 0\n",
    "    \n",
    "    # Loop through each row in the DataFrame\n",
    "    # video_source will need to be modified \n",
    "    for idx, row in df.iterrows():\n",
    "\n",
    "        # Increment the counter\n",
    "        iteration_count += 1\n",
    "    \n",
    "        # Print progress every 50 iterations\n",
    "        if iteration_count % 50 == 0:\n",
    "            print(f\"Processed {iteration_count} rows out of {len(df)}\")\n",
    "        \n",
    "        # pandas series to put into model\n",
    "        series = row\n",
    "\n",
    "        prompt = create_prompt(series = series,\n",
    "                  lm_type = 'lm',\n",
    "                  whole = False,\n",
    "                  price = False\n",
    "                 )\n",
    "\n",
    "        \n",
    "        prompt_output = inference_model(prompt = prompt,\n",
    "                        model_source =  model_source,\n",
    "                        model_name = model_name,\n",
    "                        temperature = 0,)\n",
    "        \n",
    "        \n",
    "        # Append results to output DataFrame using pd.concat\n",
    "        new_row = pd.DataFrame([{\n",
    "            'video_id': series['video_id'],\n",
    "            'video_title': series['video_title'],\n",
    "            'transcript': series['transcript'], \n",
    "            'model_source': model_source,\n",
    "            'model_name': model_name,\n",
    "            'date_of_inference': datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "            'prompt_used': prompt,\n",
    "            'prompt_output': prompt_output,\n",
    "            'video_source': None\n",
    "        }])\n",
    "    \n",
    "        output_df = pd.concat([output_df, new_row], ignore_index=True)\n",
    "    \n",
    "    # Save the output for this model to a separate CSV file\n",
    "    today = datetime.now()\n",
    "    output_df.to_csv(\n",
    "        f'llm_prompt_s_transcript_outputs/{model_name.replace(\"/\", \"_\")}_{today.strftime(\"%d_%m_%Y\")}.csv',\n",
    "        index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For segments, i dont output the ```segment_transcript```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df # concat date of inference to file name when exporting to csv \"<date>____.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
