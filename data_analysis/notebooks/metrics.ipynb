{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data_source/VideoConviction - with final refined prices.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if 'Unnamed: 0' exists in the DataFrame columns and drop it if present\n",
    "if 'Unnamed: 0' in df.columns:\n",
    "    df.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df Columns:\n",
      "--------------------\n",
      "id\n",
      "derived_inner_id\n",
      "video_id\n",
      "start\n",
      "end\n",
      "action\n",
      "action_source\n",
      "conviction_score\n",
      "ticker_name\n",
      "action_date\n",
      "price\n",
      "quantity\n",
      "video_title\n",
      "annotation_id\n",
      "is_rec_present\n",
      "original_inner_id\n",
      "original_video_title\n",
      "publishedAt\n",
      "channelId\n",
      "channelTitle\n",
      "videoDescription\n",
      "tags\n",
      "defaultAudioLanguage\n",
      "duration\n",
      "isCaptionAvailable\n",
      "viewCount\n",
      "likeCount\n",
      "favoriteCount\n",
      "commentCount\n",
      "comments\n",
      "channelDescription\n",
      "channelViewCount\n",
      "channelSubscriberCount\n",
      "videoCount\n",
      "channelCategory\n",
      "transcript\n",
      "youtube_video_url\n",
      "segment_transcript\n"
     ]
    }
   ],
   "source": [
    "# Print column names in a pretty format\n",
    "column_names = \"\\n\".join(df.columns)\n",
    "print(\"df Columns:\\n\" + \"-\"*20 + \"\\n\" + column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check 1: If all compulsory column values are present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "compulsory_fields = [\"start\", \"end\", \"action\", \"action_source\", \"conviction_score\", \"ticker_name\", \"video_title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find rows where any of the specified columns have empty (NaN) values\n",
    "filtered_df = df[df['is_rec_present'] == 'Yes']\n",
    "empty_rows = filtered_df[filtered_df[compulsory_fields].isna().any(axis=1)]\n",
    "\n",
    "# Print row numbers (index + 1 for human-readable row numbers)\n",
    "for index in empty_rows.index:\n",
    "    print(f\"Row {index + 1} has empty values in the specified columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric: Number of Annotated datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_columns = [\"start\", \"end\", \"action\", \"action_source\", \"conviction_score\", \"ticker_name\",\n",
    "                      \"action_date\", \"price\", \"quantity\", \"video_title\", \"is_rec_present\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(760, 38)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start               687\n",
      "end                 687\n",
      "action              687\n",
      "action_source       687\n",
      "conviction_score    687\n",
      "ticker_name         687\n",
      "action_date          19\n",
      "price               395\n",
      "quantity              7\n",
      "video_title         760\n",
      "is_rec_present      760\n",
      "dtype: int64\n",
      "Total non-NaN values: 6063\n"
     ]
    }
   ],
   "source": [
    "# For counts per column\n",
    "non_nan_counts = df[annotated_columns].notna().sum()\n",
    "print(non_nan_counts)\n",
    "\n",
    "# For total count across all columns\n",
    "total_non_nan = df[annotated_columns].notna().sum().sum()\n",
    "print(\"Total non-NaN values:\", total_non_nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric: Number of Total Datapoints (excluding ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-NaN counts for each column:\n",
      "id                        760\n",
      "video_id                  760\n",
      "start                     687\n",
      "end                       687\n",
      "action                    687\n",
      "action_source             687\n",
      "conviction_score          687\n",
      "ticker_name               687\n",
      "action_date                19\n",
      "price                     395\n",
      "quantity                    7\n",
      "video_title               760\n",
      "is_rec_present            760\n",
      "publishedAt               760\n",
      "channelId                 760\n",
      "channelTitle              760\n",
      "videoDescription          760\n",
      "tags                      730\n",
      "defaultAudioLanguage      638\n",
      "duration                  760\n",
      "isCaptionAvailable        760\n",
      "viewCount                 760\n",
      "likeCount                 754\n",
      "favoriteCount             760\n",
      "commentCount              726\n",
      "comments                  760\n",
      "channelDescription        760\n",
      "channelViewCount          760\n",
      "channelSubscriberCount    760\n",
      "videoCount                760\n",
      "channelCategory           760\n",
      "transcript                760\n",
      "youtube_video_url         760\n",
      "segment_transcript        687\n",
      "dtype: int64\n",
      "\n",
      "Total non-NaN values: 23278\n"
     ]
    }
   ],
   "source": [
    "# Define the columns you want to exclude\n",
    "exclude_columns = [\n",
    "    \"derived_inner_id\", \n",
    "    \"annotation_id\", \n",
    "    #\"annotator\", \n",
    "    \"original_inner_id\", \n",
    "    \"original_video_title\"\n",
    "]\n",
    "\n",
    "# Drop the excluded columns\n",
    "df_filtered = df.drop(columns=exclude_columns)\n",
    "\n",
    "# Count non-NaN values for each column in the filtered DataFrame\n",
    "column_counts = df_filtered.count()\n",
    "\n",
    "# Print the non-NaN count for each column\n",
    "print(\"Non-NaN counts for each column:\")\n",
    "print(column_counts)\n",
    "\n",
    "# Calculate the total non-NaN count\n",
    "total_non_nan = column_counts.sum()\n",
    "print(\"\\nTotal non-NaN values:\", total_non_nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric: Time range for earliest and latest video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earliest publishedAt: 2018-01-01 22:00:01+00:00\n",
      "Latest publishedAt: 2024-07-10 15:45:05+00:00\n"
     ]
    }
   ],
   "source": [
    "df['publishedAt'] = pd.to_datetime(df['publishedAt'])\n",
    "\n",
    "# Find the earliest published date\n",
    "earliest = df['publishedAt'].min()\n",
    "\n",
    "# Find the latest published date\n",
    "latest = df['publishedAt'].max()\n",
    "\n",
    "print(\"Earliest publishedAt:\", earliest)\n",
    "print(\"Latest publishedAt:\", latest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric: Total Video Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Duration: 2558.3 minutes\n",
      "Total Duration: 42.638333333333335 hours\n"
     ]
    }
   ],
   "source": [
    "df_unique = df.drop_duplicates(subset='video_id', keep='first')\n",
    "\n",
    "# Sum the 'duration' column from the deduplicated dataframe\n",
    "total_duration = df_unique['duration'].sum()\n",
    "\n",
    "print(\"Total Duration:\", total_duration/(60), \"minutes\")\n",
    "print(\"Total Duration:\", total_duration/(60*60), \"hours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric: Average Video Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average duration (in minutes): 8.88298611111111\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicate rows based on 'video_ids'\n",
    "df_unique = df.drop_duplicates(subset='video_id', keep='first')\n",
    "\n",
    "# Calculate the average of the 'duration' column\n",
    "average_duration = df_unique['duration'].mean()\n",
    "\n",
    "# Print the result\n",
    "print(\"Average duration (in minutes):\", average_duration/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This comes to 8 minutes 52 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric: Top 20 ticker names (frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ticker_name\n",
      "TSLA     26\n",
      "NVDA     11\n",
      "AMZN     10\n",
      "AAPL     10\n",
      "MSFT      8\n",
      "NIO       7\n",
      "F         6\n",
      "SOFI      6\n",
      "ZM        5\n",
      "PLTR      5\n",
      "ORCL      5\n",
      "GOOG      5\n",
      "GOOGL     5\n",
      "AVGO      5\n",
      "CRWD      4\n",
      "BABA      4\n",
      "DKNG      4\n",
      "CGC       4\n",
      "AMD       4\n",
      "FTNT      4\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get the frequency of each ticker_name and select the top 20\n",
    "top10 = df['ticker_name'].value_counts().head(20)\n",
    "\n",
    "# Print the top 20 most common ticker names with their frequencies\n",
    "print(top10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric: number of video segments (from is_rec_present == \"Yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of segments: 687\n"
     ]
    }
   ],
   "source": [
    "# Filter rows where is_rec_present is \"Yes\"\n",
    "filtered_df = df[df['is_rec_present'] == \"Yes\"]\n",
    "\n",
    "# Count the number of rows\n",
    "row_count = filtered_df.shape[0]\n",
    "print(\"Number of segments:\", row_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric: Average video segment duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average segment length (in minutes): 1.9124043514096105\n"
     ]
    }
   ],
   "source": [
    "# Calculate the difference for each row (end - start)\n",
    "df_new = df.copy()\n",
    "df_new['difference'] = df_new['end'] - df_new['start']\n",
    "\n",
    "# Compute the average of the differences\n",
    "average_difference = df_new['difference'].mean()\n",
    "\n",
    "print(\"Average segment length (in minutes):\", average_difference/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric: number of unique channel ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique channelId: 22\n"
     ]
    }
   ],
   "source": [
    "unique_channel_count = df['channelId'].nunique()\n",
    "print(\"Number of unique channelId:\", unique_channel_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric: min and max channel views and subscribers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     channelSubscriberCount  channelViewCount\n",
      "min                   21900           1340097\n",
      "max                  733000         114942285\n"
     ]
    }
   ],
   "source": [
    "# Compute min and max for both columns\n",
    "result = df[['channelSubscriberCount', 'channelViewCount']].agg(['min', 'max'])\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
